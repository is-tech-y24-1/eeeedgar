# Сборщик мусора. Генетический алгоритм

## Этап 1

### Написание минимальной работающей программы

Был использован [шаблон из организации](https://github.com/is-tech-y24-1/GeneticAlgoTemplate).

Задача - найти маршрут из одной точки в другую, избегая препятствия.

Для этого помимо сущностей, представленных в шаблоне, была создана новая - траектория *(Trajectory)*.
Она представляла из себя список векторов - перемещений точки на каждой итерации.

В новом решении каждое перемещение для каждой из точек считается случайным образом с условием, что точка не выйдет за границы холста и не попадет в препятствие.

Обнаружив, что отрисовка круглых препятствий не зависит от их радиуса, исправим это. Теперь фактический радиус круга соответствует толщине его обводки.

![Картинка из UI с найденным решением](./img/display-1.png)

## Этап 2

### Анализ работы программы с помощью dotTrace и dotMemory

Для анализа производительности генетического алгоритма напишем реализацию его запуска без UI.

![Результат первого запуска в dotTrace](./img/dottrace-1.png)

![Функция Mutate крупным планом при первом запуске в dotTrace](./img/dottrace-mutate-1.png)

Видим, что более 40% времени занимает функция ToArray() - очень плохо, надо оптимизировать.

Возможное решение - использовать такие структуры, чтобы не требовалось постоянное копирование массива.

![Результат первого запуска в dotMemory](./img/dotmemory-1.png)

Видим, что сборщик мусора часто работает - очень плохо, надо фиксить.

Возможное решение - использование таких структур, чтобы не требовалось пересоздавать долгоживущие объекты.

## Этап 3

### Оптимизация решения

#### Проблема 1

Одна из проблем заключалась в том, что при сортировке массива траекторий приходилось вызывать метод ToArray(), что занимало и время, и требовало много памяти.
Решение - хранить траектории в списке. Список траекторий постоянен, поэтому проблемы копирования при увеличении листа не будет.

```csharp
private List<Trajectory> _trajectories;
```

Мы заранее знаем количество траекторий. И, исходя из задачи, предполагаем, что оно будет достаточно велико.
Поэтому создавая пустой список и добавляя к нему траектории, мы будем сталкиваться с нехваткой _Capacity_, из-за чего списки будут пересоздаваться. Чтобы избежать этого, сразу создадим список нужного нам размера.

```csharp
_trajectories = new List<Trajectory>(_pointCount);

for (var i = 0; i < _pointCount; i++)
{
    _trajectories.Add(new Trajectory(_iterationLimit));
}
```

![Результат в dotTrace после замены массива траекторий на список](./img/dottrace-2.png)

Теперь много времени уходит на подсчет фитнес-функции. Исправим это, считая фитнес для каждой траектории только один раз за итерацию и храня его полем.

```csharp
foreach (var trajectory in _trajectories)
{
    trajectory.Fitness = _math.Fitness(trajectory.Result);
}
```

![Результат в dotTrace после сохранения фитнеса](./img/dottrace-3.png)

Стало лучше!

#### Проблема 2

Теперь будем избавляться от частого создания долгоживущих элементов.

Сейчас точки траекторий хранятся в списке. На каждой итерации к списку добавляется новая точка, списки не влезают в рамки, из-за чего регулярно создаются новые.

Как от этого избавиться? На каждой итерации мы добавляем к траектории по одной точке.
Зная заранее максимальное количество итераций, мы знаем также и максимальное количество точек в траектории,
значит, можем хранить точки в массиве.

```csharp
namespace GeneticAlgo.Shared.Models;

public class Trajectory
{
    private readonly Point[] _points;
    private int _pointCount;

    public Point Result => _points[_pointCount - 1];
    public double Fitness { get; set; }

    public int Length => _pointCount;

    public Point[] Points => _points;

    public Trajectory(int maxLength)
    {
        _points = new Point[maxLength];
        _points[0] = new Point(0, 0);
        _pointCount = 1;
    }

    public void AddPoint(Point point)
    {
        _points[_pointCount] = point;
        _pointCount++;
    }
}
```

![Результат в dotMemory после хранения точек в массивах](./img/dotmemory-4.png)

Отлично, у сборщика мусора почти нет работы, нам не нужно лишний раз тратить вычислительные ресурсы.